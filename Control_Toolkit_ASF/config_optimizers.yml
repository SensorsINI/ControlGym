cem-tf:
  seed:                               # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  cem_outer_it: 4                    #how many outer iterations to use
  cem_initial_action_stdev: 0.5
  num_rollouts: 200          #how many rollouts per outer cem iteration
  cem_stdev_min: 0.01
  cem_best_k: 40
  warmup: false
  warmup_iterations: 250
cem-gmm-tf:
  seed:                               # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  cem_outer_it: 4                    #how many outer iterations to use
  num_rollouts: 200          #how many rollouts per outer cem iteration
  cem_stdev_min: 0.01
  cem_initial_action_stdev: 0.5
  cem_best_k: 40
cem-naive-grad-tf:
  seed:                               # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  cem_outer_it: 4                       # how many outer iterations to use
  num_rollouts: 200                     # how many rollouts per outer cem iteration
  cem_stdev_min: 0.1
  cem_initial_action_stdev: 0.5
  cem_best_k: 40
  learning_rate: 0.05
  gradmax_clip: 10
cem-grad-bharadhwaj-tf:
  seed:                               # If null, random seed based on datetime is used
  mpc_horizon: 50                       # steps
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  num_rollouts: 32
  cem_best_k: 8
  cem_outer_it: 4
  cem_initial_action_stdev: 0.5
  cem_stdev_min: 1.e-6
  gradmax_clip: 5
  warmup: false
  warmup_iterations: 250
gradient-tf:
  seed:                                 # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  rtol: 1.0e-3
  gradient_steps: 4
  num_rollouts: 32
  initial_action_stdev: 0.5
  gradmax_clip: 5
  warmup: false
  warmup_iterations: 250
mppi-optimize-tf:
  seed:                                 # If null, random seed based on datetime is used
  mppi_LR: 0.02
  adam_beta_1: 0.4                      #default: 0.9
  adam_beta_2: 0.8                      #default: 0.999
  adam_epsilon: 1.0e-7                  #default: 1.0e-7
  gradmax_clip: 1000
  mpc_horizon: 40                       # steps
  num_rollouts: 400                     # Number of Monte Carlo samples
  cc_weight: 1.0
  R: 1.0                                # How much to punish Q
  LBD: 100.0                            # Cost parameter lambda
  NU: 1000.0                            # Exploration variance
  SQRTRHOINV: 0.02
  period_interpolation_inducing_points: 10                #interpolation stepsize when sampling, a random point is chosen every period_interpolation_inducing_points and horizon points in between are linearly interpolated
  optim_steps: 10
dist-adam-resamp2-tf:
  seed:                                 # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  period_interpolation_inducing_points: 10                #interpolation stepsize when sampling, a random point is chosen every period_interpolation_inducing_points and horizon points in between are linearly interpolated
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  gradmax_clip: 5
  rtol: 1.0e-3
  num_rollouts: 32
  opt_keep_k_ratio: 0.25
  outer_its: 4
  resamp_per: 10
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
rpgd-tf:
  seed:                                 # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_DISTRIBUTION: uniform         # "normal" or "uniform"
  period_interpolation_inducing_points: 5                #interpolation stepsize when sampling, a random point is chosen every period_interpolation_inducing_points and horizon points in between are linearly interpolated
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  gradmax_clip: 5
  rtol: 1.0e-3
  num_rollouts: 32
  opt_keep_k_ratio: 0.25
  outer_its: 4
  resamp_per: 10
  sample_stdev: 0.5
  sample_mean: 0.0
  sample_whole_control_space: true # If true bounds of uniform distribution are set to max limits of action space, otherwise see below
  uniform_dist_max: 0.8 # only applies if SAMPLING_DISTRIBUTION: uniform AND sample_whole_control_space: false
  uniform_dist_min: -0.8 # only applies if SAMPLING_DISTRIBUTION: uniform AND sample_whole_control_space: false
  shift_previous: 1  # How much to shift solution from previous timestep, to serve as the guess for current timestep
  warmup: false
  warmup_iterations: 250
rpgd-me-tf:
  seed:                                 # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_DISTRIBUTION: uniform          # "normal" or "uniform"
  period_interpolation_inducing_points: 2                # interpolation stepsize when sampling, a random point is chosen every period_interpolation_inducing_points and horizon points in between are linearly interpolated
  learning_rate: 0.5
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  maximum_entropy_alpha: 1.0e+0
  gradmax_clip: 5
  rtol: 1.0e-3
  num_rollouts: 32
  opt_keep_k_ratio: 0.25
  outer_its: 4
  resamp_per: 10
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
rpgd-me-param-tf:
  seed:                                 # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_DISTRIBUTION: uniform          # "normal" or "uniform"
  period_interpolation_inducing_points: 1                # interpolation stepsize when sampling, a random point is chosen every period_interpolation_inducing_points and horizon points in between are linearly interpolated
  learning_rate: 0.5
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  maximum_entropy_alpha: 1.0e-1
  gradmax_clip: 5
  rtol: 1.0e-3
  num_rollouts: 32
  opt_keep_k_ratio: 0.25
  outer_its: 4
  resamp_per: 10
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
rpgd-ml-tf:
  seed:                                 # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_DISTRIBUTION: uniform          # "normal" or "uniform"
  period_interpolation_inducing_points: 1                #interpolation stepsize when sampling, a random point is chosen every period_interpolation_inducing_points and horizon points in between are linearly interpolated
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  maximum_entropy_alpha: 0.1
  gradmax_clip: 10
  rtol: 1.0e-3
  num_rollouts: 32
  opt_keep_k_ratio: 0.25
  outer_its: 4
  resamp_per: 1
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
rpgd-particle-tf:
  seed:                                 # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  SAMPLING_DISTRIBUTION: uniform
  period_interpolation_inducing_points: 4                #interpolation stepsize when sampling, a random point is chosen every period_interpolation_inducing_points and horizon points in between are linearly interpolated
  learning_rate: 0.05
  adam_beta_1: 0.9
  adam_beta_2: 0.999
  adam_epsilon: 1.0e-08
  gradmax_clip: 10
  rtol: 1.0e-3
  num_rollouts: 32
  opt_keep_k_ratio: 0.25
  outer_its: 4
  resamp_per: 1
  sample_stdev: 0.5
  warmup: false
  warmup_iterations: 250
mppi-var-tf:
  seed:                               # If null, random seed based on datetime is used
  mpc_horizon: 40                       # steps
  num_rollouts: 400                     # Number of Monte Carlo samples
  period_interpolation_inducing_points: 10                #interpolation stepsize when sampling, a random point is chosen every period_interpolation_inducing_points and horizon points in between are linearly interpolated
  cc_weight: 1.0
  R: 1.0                                # How much to punish Q
  # mc stands for mathematical correct, as this controller uses the formula from the paper
  LBD_mc: 10.0                          # Cost parameter lambda
  SQRTRHOINV_mc: 0.002                  # Sampling variance
  NU_mc: 20.0                           # Exploration variance
  LR: 1000                              # Learning rate for adaption of variance, !!! Set to 0 to retrieve a mppi version in accordance with mppi paper
  STDEV_min: 0.01                       # Maximal variance for sampling
  STDEV_max: 10                         # Minimal sampling variance for sampling
  max_grad_norm: 100000                 # max norm of gradient such that ||gradient||_2
mppi:
  seed:                                 # Seed for rng, for MPPI only, put null to set random seed (do it when you generate data for training!)
  mpc_horizon: 40                       # steps
  num_rollouts: 3500                    # Number of Monte Carlo samples
  cc_weight: 1.0
  R: 1.0                                # How much to punish Q
  LBD: 100.0                            # Cost parameter lambda
  NU: 1000.0                            # Exploration variance
  SQRTRHOINV: 0.1                       # Sampling variance
  period_interpolation_inducing_points: 10                #interpolation stepsize when sampling, a random point is chosen every period_interpolation_inducing_points and horizon points in between are linearly interpolated
random-action-tf:
  seed:                               # Seed for rng, for MPPI only, put null to set random seed (do it when you generate data for training!)
  mpc_horizon: 40                      # steps
  num_rollouts: 32
nlp-forces:
  seed: null
  mpc_horizon: 40                       # steps
  num_rollouts: 1
  initial_guess: PD                     # no_action or PD
#  generate_new_solver: False
  generate_new_solver: True
  terminal_constraint_at_target: False
  terminal_set_width: 0.0               # Set to <=0 for no terminal set
  environment_specific_parameters:
    cartpole_simulator:
      dynamics: cartpole_non_linear_dynamics
      cost: cartpole_simulator1
      target: cartpole_target
      dt: 0.02                          # Integration stepsize, make sure matches the one of the environment
      optimize_over: [0, 1, 4, 5]       # Optimization variables idxs: [angle, ang vel, pos, vel]
      is_angle: [0]                      # Which of the idxs refer to an angle
      action_max: [1.0]
      state_max: [6.284, 100.0, 0.198, 0.8]   # State constraints [pi, v ang. max, TrackHalfLegth, vmax]
      idx_terminal_set: [2]             # Which state idx are affected by terminal set
      q: [100.0, 0.0, 00.0, 0.0]        # State cost
      r: [0.0]                          # Input cost
    pendulum:
      dynamics: pendulum_dynamics
      cost: pendulum
      dt: 0.05                          # Integration stepsize, make sure matches the one of the environment
      optimize_over: [0, 1]             # Optimization variables idxs: [angle, ang vel]
      is_angle: []                     # Which of the idxs refer to an angle
      action_max: [ 2.0 ]               # Input constraints
      state_max: [ 6.285, 8.0]          # State constraints [2pi, v ang. max]
      idx_terminal_set: [0]
      q: [ 100.0, 0.0]                  # State cost
      r: [ 0.0 ]                        # Input cost
    continuous_mountaincar:
      dynamics: continuous_mountaincar
      cost: continuous_mountaincar
      dt: 1.0                           # Integration stepsize, make sure matches the one of the environment
      optimize_over: [ 0, 1 ]           # Optimization variables idxs: [pos, vel]
      is_angle: []                      # Which of the idxs refer to an angle
      action_max: [ 1.0 ]               # Input constraints
      state_max: [ 1.2, 0.07 ]          # State constraints [finish, v max]
      idx_terminal_set: [ 0 ]
      q: [ 10.0, 0.0 ]                  # State cost
      r: [ 0.0 ]                        # Input cost
    acrobot:
      dynamics: acrobot_dynamics
      cost:
      dt: 0.1                           # Integration stepsize, make sure matches the one of the environment
      optimize_over: [0, 1, 2, 3]       # Optimization variables idxs: [th1, th2, dth1, dth2]
      is_angle: [0, 1]                  # Which of the idxs refer to an angle
      action_max: [1.0]                 # Input constraints
      state_max: [6.285, 6.285, 12.56637, 28.2743338823]          # State constraints [finish, v max]
      q: [10.0, 0.0, 0.0, 0.0]                    # State cost
      r: [0.0]                          # Input cost
